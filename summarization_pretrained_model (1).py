# -*- coding: utf-8 -*-
"""Summarization pretrained model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jz00_cn9zg0dBf2RR518G1tyw7FEtsTE
"""

import pandas as pd
import numpy as np

!pip install transformers

import warnings
warnings.filterwarnings('ignore')

from transformers import pipeline

model_summary = pipeline("summarization", model="facebook/bart-large-cnn")

def generate_chunks(inp_str):
  max_chunk = 500
  inp_str = inp_str.replace('.','.<eos>')
  inp_str = inp_str.replace('?','?<eos>')
  inp_str= inp_str.replace('!','!<eos>')
  sentences = inp_str.split('<eos>')
  current_chunk = 0
  chunk = []
  for sentence in sentences:
    if len(chunk) == current_chunk +1:
      if len(chunk[current_chunk]) + len(sentence.split(' ')) <= max_chunk:
        chunk[current_chunk].extend(sentence.split(' '))
      else:
        current_chunk +=1
        chunk.append(sentence.split(' '))
    else:
      chunk.append(sentence.split(' '))
  for chunk_id in range(len(chunk)):
    chunk[chunk_id] = ' '.join(chunk[chunk_id])

  return chunk

sentence_summary= 'Please Paste your Article : NLP or Natural Language Processing is an AI field focused on computer-human language interaction. It aims to enable machines to understand, interpret, and generate human text meaningfully.Machine translation helps break language barriers between cultures. Virtual assistants like Siri and Alexa use advanced techniques to respond to voice commands. Sentiment analysis examines texts to identify positive or negative opinions.The evolution of large language models like GPT-4 and BERT continues to push boundaries in what machines can achieve with human language. Multimodal AI systems that combine text, audio, and visual processing are creating more comprehensive understanding capabilities. Ethical considerations around bias mitigation and responsible AI deployment are becoming increasingly important as these technologies become more integrated into daily life. The ongoing research in explainable AI aims to make NLP systems more transparent and trustworthy.'

chunks= generate_chunks(sentence_summary)

res = model_summary(chunks, max_length = 100 , min_length = 10)
text = ' '.join([summ['summary_text'] for summ in res ])

text

model_summary.save_pretrained('./saved_models/summarization_model')